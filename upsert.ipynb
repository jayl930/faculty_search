{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import gradio as gr\n",
    "from langchain_community.document_loaders import UnstructuredPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from pinecone import Pinecone\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "AZURE_DEPLOYMENT_NAME = os.getenv(\"AZURE_DEPLOYMENT_NAME\")\n",
    "AZURE_EMBEDDING = os.getenv(\"AZURE_EMBEDDING\")\n",
    "\n",
    "pc = Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    azure_deployment=AZURE_EMBEDDING,\n",
    "    openai_api_version=\"2024-03-01-preview\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "folder_path = 'people_pdfs'\n",
    "csv_filename = 'search_people.csv'\n",
    "\n",
    "# List to store the filenames\n",
    "file_names = []\n",
    "\n",
    "# Traverse the directory and add file names to the list\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename == '.DS_Store':\n",
    "        continue\n",
    "    file_names.append(filename)\n",
    "\n",
    "# Write the list of filenames to a CSV file\n",
    "with open(csv_filename, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    for name in file_names:\n",
    "        writer.writerow([name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = PineconeVectorStore(index_name='grants', embedding=embeddings)\n",
    "data = pd.read_csv('grants.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in data.iterrows():\n",
    "    time.sleep(0.2)\n",
    "    text = row['summary'] if not pd.isna(row['summary']) else \"\"\n",
    "    metadata = {\n",
    "        \"source\": row['source'],\n",
    "        \"date\": row['post_date'],\n",
    "        \"uid\": row['dpi_uid']\n",
    "    }\n",
    "    vectorstore.add_texts([text], metadatas=[metadata])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = vectorstore.similarity_search_with_score(\n",
    "    \"\"\"\n",
    "    natural language processing\n",
    "    \"\"\", 20, filter={\n",
    "        \"source\": \"NIH\",\n",
    "        \"$and\": [{ \"date\": { \"$gte\": 202305 } }, { \"date\": { \"$lte\": 202401 } }]\n",
    "    },)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UID: aBe7AZQlc2GBR/LKYyNublN8BrQxsbUmgfRJIWKw1jM= Score: 0.317472905\n",
      "UID: V91W67xUvXJzTwgMABJvrUTHrbDDkWtjQ1X1K7IySc0= Score: 0.250626832\n",
      "UID: L8B1lJNgfTg7k6DMoUb3O3oU/KJGCSs6QHF4OuHV3rg= Score: 0.239333555\n",
      "UID: qEkF/X/VQAkalKVjnOay0pApk+CmwqW8aeF6Yw+1p0o= Score: 0.232206762\n",
      "UID: Ck1BgpfvXM+6/3ccjuxp185kr9JaYfgqa3SJqXcrXkM= Score: 0.229872\n",
      "UID: LjYRPr95k7rPswZrctcnQJV1ChjBYkuIRV6ZOWYnijQ= Score: 0.223694399\n",
      "UID: etKb/2evKNYolHjaKwjy3f7f8gSI+BPnKmYfLZ/QYOY= Score: 0.222091526\n",
      "UID: 1H3ABy2+7oJ6BE1ledtFF3owu31c//Na1MQkQ7m9odI= Score: 0.217852876\n",
      "UID: aJXi7gLe7pLIhIf6WhPxFePRn1EeHLtJlbvbRtpkEPw= Score: 0.217852876\n",
      "UID: cOwz7GMxN4f8euT+gJrZ6sgGjIUlR3U5KPOh06KtcYo= Score: 0.217852876\n",
      "UID: uz9Nb+R5vrzXLOQcGMTlP77++u+LGUsZuHOfFMxPPQk= Score: 0.217852876\n",
      "UID: 1y1Iol82aJuPmw1lQCx74a28wzPNJKApqtZcDv395XM= Score: 0.217852876\n",
      "UID: oAr0WXLU0JD771YW64HVV2wlnXoDhMEYRavm+0cajcA= Score: 0.217852876\n",
      "UID: KL0lejo6NgrGW6MRvDhQTqqePYm5n/djjzKT+MibWoc= Score: 0.217852876\n",
      "UID: EPBE3+vq00QlnYI1zZafuPxlMhD2nlIKuFleBb+V1Sk= Score: 0.216370374\n",
      "UID: rsxg8tPOOHcgFqJUzQRuF6lCnLXPCMnLztg6W24REKs= Score: 0.215314955\n",
      "UID: LjYRPr95k7rPswZrctcnQJV1ChjBYkuIRV6ZOWYnijQ= Score: 0.208996072\n",
      "UID: F5njJwDR60guhoGw/AFzPR+Ozq48rnJ0Cj8j4GlWgQQ= Score: 0.208032951\n",
      "UID: 5GYFXZoryAUV8B4D2jygSC0Tpsis6DvLiUiVs33276Q= Score: 0.200848207\n",
      "UID: ipQWcDQpBkpzv5h4GjFvNDAH7mV7UmuXxEz1xfHCZ2U= Score: 0.198810786\n"
     ]
    }
   ],
   "source": [
    "results = [(doc.metadata['uid'], score) for doc, score in docs]\n",
    "\n",
    "for result in results:\n",
    "    print(\"UID:\", result[0], \"Score:\", result[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## researchers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomFileLoader(UnstructuredPDFLoader):\n",
    "    def _get_metadata(self) -> dict:\n",
    "        file_name = os.path.basename(self.file_path)\n",
    "        return {\"source\": file_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '/Users/jaylee/Documents/work/dpi/pdf3'\n",
    "for filename in os.listdir(folder_path):\n",
    "      time.sleep(0.1)\n",
    "      if filename == '.DS_Store':\n",
    "            continue\n",
    "      file_path = os.path.join(folder_path, filename)\n",
    "      splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder()\n",
    "      loader = CustomFileLoader(file_path)\n",
    "      docs = loader.load_and_split(text_splitter=splitter)\n",
    "\n",
    "      vectorstore = PineconeVectorStore.from_documents(docs, embeddings, index_name=\"dpi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = PineconeVectorStore(index_name='dpi', embedding=embeddings)\n",
    "retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Chilin Shih: 0.450808406\n",
      "2. Heng Ji: 0.430762917\n",
      "3. Hao Peng: 0.42467308\n",
      "4. Chengxiang Zhai: 0.412713766\n",
      "5. Jonathan E Dunn: 0.409267366\n",
      "6. Nickvash Kani: 0.408924401\n",
      "7. Suma Pallathadka Bhat: 0.404810667\n",
      "8. Dilek Hakkani Tur: 0.404101938\n",
      "9. Heng Ji: 0.398736149\n",
      "10. Heng Ji: 0.396744192\n",
      "11. Julia Constanze Hockenmaier: 0.391444176\n",
      "12. Suma Pallathadka Bhat: 0.390879512\n",
      "13. Heng Ji: 0.388903677\n",
      "14. Chengxiang Zhai: 0.388726532\n",
      "15. Jon Anthony Willits: 0.387324393\n",
      "16. Huan Zhang: 0.385635346\n",
      "17. Jiawei Han: 0.385319144\n",
      "18. Jana Diesner: 0.383365512\n",
      "19. Heng Ji: 0.382180631\n",
      "20. Catherine Lesley Blake: 0.379984319\n"
     ]
    }
   ],
   "source": [
    "docs = vector_store.similarity_search_with_score(\n",
    "    \"\"\"\n",
    "    natural language processing\n",
    "    \"\"\", 20)\n",
    "for i, (doc, score) in enumerate(docs, start=1):\n",
    "    source = doc.metadata['source']\n",
    "    source_without_extension = source.split('.pdf')[0]\n",
    "    print(f\"{i}. {source_without_extension}: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Chilin Shih: 0.450808406\n",
      "2. Heng Ji: 0.430762917\n",
      "3. Hao Peng: 0.42467308\n",
      "4. Chengxiang Zhai: 0.412713766\n",
      "5. Jonathan E Dunn: 0.409267366\n",
      "6. Nickvash Kani: 0.408924401\n",
      "7. Suma Pallathadka Bhat: 0.404810667\n",
      "8. Dilek Hakkani Tur: 0.404101938\n",
      "9. Julia Constanze Hockenmaier: 0.391444176\n",
      "10. Jon Anthony Willits: 0.387324393\n",
      "11. Huan Zhang: 0.385635346\n",
      "12. Jiawei Han: 0.385319144\n",
      "13. Jana Diesner: 0.383365512\n",
      "14. Catherine Lesley Blake: 0.379984319\n"
     ]
    }
   ],
   "source": [
    "docs = vector_store.similarity_search_with_score(\n",
    "    \"\"\"\n",
    "    natural language processing\n",
    "    \"\"\", 20)\n",
    "\n",
    "seen_sources = set()\n",
    "unique_docs = []\n",
    "\n",
    "for doc, score in docs:\n",
    "    source = doc.metadata['source']\n",
    "    source_without_extension = source.split('.pdf')[0]\n",
    "    \n",
    "    # Check if the source has already been included\n",
    "    if source_without_extension not in seen_sources:\n",
    "        seen_sources.add(source_without_extension)\n",
    "        unique_docs.append((source_without_extension, score))\n",
    "\n",
    "# Now, print the unique sources with their scores\n",
    "for i, (source, score) in enumerate(unique_docs, start=1):\n",
    "    print(f\"{i}. {source}: {score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
